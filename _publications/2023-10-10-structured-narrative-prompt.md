---
title: "A structured narrative prompt for prompting narratives from large language models: Sentiment assessment of chatgpt-generated narratives and real tweets"
collection: publications
category: manuscripts
permalink: /publication/2023-structured-narrative-prompt
excerpt: 'This paper presents a structured narrative prompt for generating narratives from large language models and assesses the sentiment of ChatGPT-generated narratives and real tweets.'
date: 2023-01-01
venue: 'Future Internet'
paperurl: 'http://rossgore.github.io/files/structured_narrative_prompt.pdf'
citation: 'Lynch, Christopher J; Jensen, Erik J; Zamponi, Virginia; OBrien, Kevin; Frydenlund, Erika; Gore, Ross. (2023). "A structured narrative prompt for prompting narratives from large language models: Sentiment assessment of chatgpt-generated narratives and real tweets". <i>Future Internet</i>. 15(12), 375.'
---
Large language models (LLMs) excel in providing natural language responses that sound authoritative, reflect knowledge of the context area, and can present from a range of varied perspectives. Agent-based models and simulations consist of simulated agents that interact within a simulated environment to explore societal, social, and ethical, among other, problems. Simulated agents generate large volumes of data and discerning useful and relevant content is an onerous task. LLMs can help in communicating agents’ perspectives on key life events by providing natural language narratives. However, these narratives should be factual, transparent, and reproducible. Therefore, we present a structured narrative prompt for sending queries to LLMs, we experiment with the narrative generation process using OpenAI’s ChatGPT, and we assess statistically significant differences across 11 Positive and Negative Affect Schedule (PANAS) sentiment levels between the generated narratives and real tweets using chi-squared tests and Fisher’s exact tests. The narrative prompt structure effectively yields narratives with the desired components from ChatGPT. In four out of forty-four categories, ChatGPT generated narratives which have sentiment scores that were not discernibly different, in terms of statistical significance (alpha level α=0.05), from the sentiment expressed in real tweets.